<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ollama on DillonBaird.io</title>
    <link>https://DillonBaird.io/tags/ollama/</link>
    <description>Recent content in Ollama on DillonBaird.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 11 May 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://DillonBaird.io/tags/ollama/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ollama Unleashed: The DIY LLM Powerhouse on Your Local Machine</title>
      <link>https://DillonBaird.io/blog/ollama/</link>
      <pubDate>Sat, 11 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://DillonBaird.io/blog/ollama/</guid>
      <description>&lt;p&gt;Large language models (LLMs) are powerful tools, but running them on your own can be a challenge. &lt;strong&gt;Ollama&lt;/strong&gt; simplifies this process, allowing you to run these advanced models directly on your local machine, without the need for expensive cloud services or specialized hardware. With Ollama, you gain complete control over your AI tools. Customize them to your specific needs and experiment freely without worrying about high costs. Plus, you can break free from reliance on cloud providers.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
